{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMzehe0sy5wr"
      },
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4nJmxp9zGX4"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoVWQ8AEyc-C",
        "outputId": "6b0341ee-0e3a-452a-a12e-83071e82062c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/data\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WGpzvYC2ypyS"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import svm \n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import feature_selection\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from seaborn import load_dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T9MZGJhzjrN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNv07ARGzOUm"
      },
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOsg77IBzEyo"
      },
      "outputs": [],
      "source": [
        "data = datasets.load_iris()\n",
        "X=data.data\n",
        "y=data.target\n",
        "x = PrettyTable()\n",
        "x.field_names = [\"name\",\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
        "def Model(name,X_train, X_test, y_train, y_test,check):\n",
        "  global model;\n",
        "  if(check==1):\n",
        "    model=RandomForestClassifier(n_estimators=100)\n",
        "  elif(check==2):\n",
        "    model = GaussianNB()\n",
        "  elif(check==3):\n",
        "    model = svm.SVC(kernel='linear')\n",
        "  elif(check==4):\n",
        "    model = KNeighborsClassifier(n_neighbors=3)\n",
        "  elif(check==5):\n",
        "    model = DecisionTreeClassifier()\n",
        "  elif(check==6):\n",
        "    model = LogisticRegression(random_state=0)\n",
        "    \n",
        "\n",
        "#Train the model using the training sets\n",
        "  print(model)\n",
        "  model.fit(X_train,y_train)\n",
        "  predicRd=model.predict(X_test)\n",
        "# Random forest\n",
        "  accRd = round(metrics.accuracy_score(y_test, predicRd),6)\n",
        "  f1Rd =round(metrics.f1_score(y_test, predicRd,average='macro'),6)\n",
        "  recallRd = round(metrics.recall_score(y_test, predicRd,average='macro'),6)\n",
        "  PreRd = round(metrics.precision_score(y_test, predicRd,average='macro'),6)\n",
        "  x.add_row([name, accRd, f1Rd, recallRd,PreRd])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "Model(\"RandomNotSelect\",X_train, X_test, y_train, y_test,1)\n",
        "Model(\"NaiveBayesNotSelect\",X_train, X_test, y_train, y_test,2)\n",
        "Model(\"SVMNotSelect\",X_train, X_test, y_train, y_test,3)\n",
        "X_new=feature_selection.SelectKBest(feature_selection.chi2, k=2).fit_transform(X,y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
        "Model(\"RandomHaveSelect\",X_train, X_test, y_train, y_test,1)\n",
        "Model(\"NaiveBayesHaveSelect\",X_train, X_test, y_train, y_test,2)\n",
        "Model(\"SVMHaveSelect\",X_train, X_test, y_train, y_test,3)\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qk5rdf08C70"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b52OPWPD2afi"
      },
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "id": "VRQVEZLFyG_x"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('bank.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q89LEvT7dqaZ"
      },
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vx3mfIidu4P",
        "outputId": "072f2fe0-c092-4e00-98ab-6536bec2f363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.12319477e+01 1.52853852e+03 1.56580362e+01 2.50842143e+00\n",
            " 5.13304067e+01 8.32556889e-01]\n",
            "[4.12319477e+01 1.52853852e+03 1.56580362e+01 2.50842143e+00\n",
            " 5.13304067e+01 8.32556889e-01]\n"
          ]
        }
      ],
      "source": [
        "X=data[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']]\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "print(scaler.mean_)\n",
        "scaler.transform(X)\n",
        "print(scaler.mean_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7acR0TxdvY8"
      },
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtgBmAtd0um",
        "outputId": "c05955bb-712a-4113-f701-4e2d9244df7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# data['marital'] = data['marital'].replace(['divorced','married','single','unknown'], [0,1,2,3])\n",
        "data=pd.read_csv('bank.csv')\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded_data = encoder.fit_transform(data[categorical_columns])\n",
        "numerical_columns = [c for c in data.columns if c not in categorical_columns]\n",
        "X = np.concatenate([data[numerical_columns], encoded_data], axis=1)\n",
        "data['deposit']=data['deposit'].replace(['yes','no'], [1,0])\n",
        "y = data['deposit'].values\n",
        "X[0:,7][X[0:,7] == \"yes\"] = 1\n",
        "X[0:,7][X[0:,7] == \"no\"] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2Si6d69d1nh"
      },
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, Na√ØveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ouil-cf_d8jW",
        "outputId": "cf5005bc-9db1-43d7-cec9-2a70e8013eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier()\n",
            "GaussianNB()\n",
            "KNeighborsClassifier(n_neighbors=3)\n",
            "DecisionTreeClassifier()\n",
            "+----------------------+----------+----------+----------+-----------+\n",
            "|         name         | accuracy |    f1    |  recall  | precision |\n",
            "+----------------------+----------+----------+----------+-----------+\n",
            "|   RandomHaveSelect   |   1.0    |   1.0    |   1.0    |    1.0    |\n",
            "| NaiveBayesHaveSelect | 0.999403 | 0.999402 | 0.999426 |  0.999378 |\n",
            "|    KnnHaveSelect     | 0.736638 | 0.735866 | 0.735655 |  0.736358 |\n",
            "|    TreeHaveSelect    |   1.0    |   1.0    |   1.0    |    1.0    |\n",
            "+----------------------+----------+----------+----------+-----------+\n"
          ]
        }
      ],
      "source": [
        "x = PrettyTable()\n",
        "x.field_names = [\"name\",\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "Model(\"RandomHaveSelect\",X_train, X_test, y_train, y_test,1)\n",
        "Model(\"NaiveBayesHaveSelect\",X_train, X_test, y_train, y_test,2)\n",
        "Model(\"KnnHaveSelect\",X_train, X_test, y_train, y_test,4)\n",
        "Model(\"TreeHaveSelect\",X_train, X_test, y_train, y_test,5)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SweVRB4meApP"
      },
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seFBhqCSeC7C",
        "outputId": "45f9b863-8e26-4b16-876d-c01ddb389227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier()\n",
            "GaussianNB()\n",
            "KNeighborsClassifier(n_neighbors=3)\n",
            "DecisionTreeClassifier()\n",
            "+---------------------+----------+----------+----------+-----------+\n",
            "|         name        | accuracy |    f1    |  recall  | precision |\n",
            "+---------------------+----------+----------+----------+-----------+\n",
            "|   RandomNotSelect   |   1.0    |   1.0    |   1.0    |    1.0    |\n",
            "| NaiveBayesNotSelect | 0.999403 | 0.999402 | 0.999426 |  0.999378 |\n",
            "|     KnnNotSelect    | 0.732159 | 0.731576 | 0.73147  |  0.731741 |\n",
            "|    TreeNotSelect    |   1.0    |   1.0    |   1.0    |    1.0    |\n",
            "+---------------------+----------+----------+----------+-----------+\n"
          ]
        }
      ],
      "source": [
        "x = PrettyTable()\n",
        "x.field_names = [\"name\",\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
        "np.absolute(X)\n",
        "X_new=feature_selection.SelectKBest(feature_selection.chi2, k=10).fit_transform(X,y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
        "Model(\"RandomNotSelect\",X_train, X_test, y_train, y_test,1)\n",
        "Model(\"NaiveBayesNotSelect\",X_train, X_test, y_train, y_test,2)\n",
        "Model(\"KnnNotSelect\",X_train, X_test, y_train, y_test,4)\n",
        "Model(\"TreeNotSelect\",X_train, X_test, y_train, y_test,5)\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      },
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw_-8FIf2KxW",
        "outputId": "2266dcb5-39ab-4d5a-dc22-f3124f66ff42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier()\n"
          ]
        }
      ],
      "source": [
        "data=pd.read_csv('creditcard.csv')\n",
        "data=np.absolute(data)\n",
        "x = PrettyTable()\n",
        "x.field_names = [\"name\",\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
        "X=data.iloc[0:,0:30]\n",
        "y=data.iloc[0:,30]\n",
        "X_new=feature_selection.SelectKBest(feature_selection.chi2, k=10).fit_transform(X,y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
        "Model(\"RandomHaveSelect\",X_train, X_test, y_train, y_test,1)\n",
        "Model(\"NaiveBayesHaveSelect\",X_train, X_test, y_train, y_test,2)\n",
        "Model(\"SvmHaveSelect\",X_train, X_test, y_train, y_test,3)\n",
        "Model(\"KnnHaveSelect\",X_train, X_test, y_train, y_test,4)\n",
        "Model(\"TreeHaveSelect\",X_train, X_test, y_train, y_test,5)\n",
        "Model(\"LogisticHaveSelect\",X_train, X_test, y_train, y_test,5)\n",
        "print(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok7RGkea_b7n"
      },
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}